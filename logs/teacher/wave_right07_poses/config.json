{"seed": 1, "policy": {"init_noise_std": 1.0, "actor_hidden_dims": [512, 256, 128], "critic_hidden_dims": [512, 256, 128], "activation": "elu"}, "algorithm": {"value_loss_coef": 1.0, "use_clipped_value_loss": true, "clip_param": 0.2, "entropy_coef": 0.005, "num_learning_epochs": 5, "num_mini_batches": 4, "learning_rate": 0.001, "schedule": "adaptive", "gamma": 0.99, "lam": 0.95, "desired_kl": 0.01, "max_grad_norm": 0.2}, "runner": {"path": "logs/teacher", "policy_class_name": "ActorCritic", "algorithm_class_name": "PPO", "num_steps_per_env": 24, "max_iterations": 10000000, "save_interval": 500, "checkpoint": "model_18500.pt", "resume": false, "resume_path": "logs/teacher/right2"}}